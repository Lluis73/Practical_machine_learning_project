---
title: "Prediction Assignment"
author: "Llu√≠s Ferreras"
date: "25/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

## Executive summary

The goal of this analysis is to fit a statistical learning model to predict the way in which an exercise is done, using data from accelerometers on the bell, forearm, arm and dumbell of 6 participants. Several types of models have been tested like linear discriminant analysis, boosting machine and random forests, and the final model have been tuned and selected using 5-fold cross-validation. The final model is a random forest model and we estimate out-of-sample error using 5-fold cross-validation obtaining an acccuracy ratio of 0.991. 

## Downloading and treatment of data

We download the file containing the data:

```{r}
url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url, "pml-training.csv", "curl")
pml<-read.csv("pml-training.csv", header = TRUE)
```

we create a partition of the data to train the models with 70% of the data. The other 30% of the data will be used to compute the out-of-sample accuracy. We set the seed in order to make the results reproducible.

```{r}
library(caret)
set.seed(123)
inTrain<-createDataPartition(y=pml$classe,p=0.7,list = FALSE)
training<-pml[inTrain,]; testing<-pml[-inTrain,]
```

We compute the dimensions of the training set
```{r}
dim(training)
```

We eliminate the variables related with identification of the register as name or timestamps and also the variables with a majority of 'NA' values

```{r}
reg_valid<-8
for(i in 9:160) {
     if (sum(is.na(training[,i]))==0) {
         reg_valid<-c(reg_valid,i)
     }
}
training_r<-training[,reg_valid]
```

We also eliminate variables with a lot of registers not informed (Kurtosis,skweness,max,min,amplitude)

```{r}
training_r<-training_r[,!grepl("kurtosis",colnames(training_r),fixed=TRUE)]
training_r<-training_r[,!grepl("skewness",colnames(training_r),fixed=TRUE)]
training_r<-training_r[,!grepl("max",colnames(training_r),fixed=TRUE)]
training_r<-training_r[,!grepl("min",colnames(training_r),fixed=TRUE)]
training_r<-training_r[,!grepl("amplitude",colnames(training_r),fixed=TRUE)]
```

```{r}
dim(training_r)
```

So, we are going to model the "classe" outcome (variable 53) with the other 52 variables.

## Model building process

The process to build a machine learning algorithm is to choose the model that has a lowest out-of-sample error or equivalently highest accuracy ratio. The accuracy ratio has been estimated using 5-fold cross-validation and has also been compared with the accuracy ratio computed in the testing sample.

We have dropped the variables with a majority of NA and 0 values, so we model the outcome depending on the rest of variables (52 variables).

We have fitted different models using 3 learning algorithms appropriate for classification (qualitative outcome), namely "linear discriminant analysis", "boosting machine" and "random forest".

First, We fit a "linear discriminant analysis" model to the data. We change the control options of the caret package train function in order to allow for parallel computing and make the computation faster. We use 5-fold cross-validation in order to estimate out-of-sample error using the training data.

```{r, cache=TRUE}
set.seed(123)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
cv_options<- trainControl(method="cv",number=5,allowParallel = TRUE)
mod_lda_cv5<-train(classe ~ .,method="lda",data=training_r,
                  trControl=cv_options)
stopCluster(cluster)
registerDoSEQ()
```

After having fitted the model with the cross-validation option we can use the confussion matrix to estimate accuracy ratio (I assign the result to a variable to avoid printing all the data and making this report too long)

```{r}
CM_lda_cv5<-confusionMatrix.train(mod_lda_cv5)
```

The accuracy ratio using 5-fold cross-validation is 0.7019. When we calculate the accuracy ratio using the testing sample from our partition, we get 0.696.

```{r}
CM_lda_cv5_test<-confusionMatrix(predict(mod_lda_cv5,testing),as.factor(testing$classe))
```

Both cross-validation and testing sample are estimates of out-of-sample accuracy ratios, but using different approaches.

Next, we train a "boosting machine" model using the default bootstraping method for resampling. The "gbm" train process uses in this case the resampling with bootstraping both to find/tune the best parameters with highest accuracy ratios and estimate an out-of-sample accuracy ratio without using a testing sample independent from the training sample.

```{r, cache=TRUE}
set.seed(123)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
cv_options<- trainControl(allowParallel = TRUE)
mod_gbm_res<-train(classe ~ .,method="gbm",data=training_r,
                  trControl=cv_options,verbose=FALSE)
stopCluster(cluster)
registerDoSEQ()
```

We compute the accuracy ratio using the resampling with bootstraping (0.9568) and the testing sample (0.9619).

```{r}
CM_gbm_res<-confusionMatrix.train(mod_gbm_res)
CM_gbm_res_test<-confusionMatrix(predict(mod_gbm_res,testing),as.factor(testing$classe))
```

Now, we train a "boosting machine" model changing the resampling method to 5-fold cross-validation. In this case, the 5-fold cross-validation will be used for tuning the parameters and estimate an out-of-sample accuracy ratio without using a testing sample independent from the training sample.

```{r, cache=TRUE}
set.seed(123)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
cv_options<- trainControl(method="cv",number=5,allowParallel = TRUE)
mod_gbm_cv5<-train(classe ~ .,method="gbm",data=training_r,
                   trControl=cv_options,verbose=FALSE)
stopCluster(cluster)
registerDoSEQ()
```

In this case, the accuracy ratio using 5-fold cross-validation is 0.9616 and using the testing sample is 0.9621

```{r}
CM_gbm_cv5<-confusionMatrix.train(mod_gbm_cv5)
CM_gbm_cv5_test<-confusionMatrix(predict(mod_gbm_cv5,testing),as.factor(testing$classe))
```

Finally, we fit "random forests" models to the data using resampling with bootstraping (default option for caret train function) and 5-fold cross-validation.

Training of random forest with bootstraping:

```{r, cache=TRUE}
set.seed(123)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
cv_options<- trainControl(allowParallel = TRUE)
mod_rf_res<-train(classe ~ .,method="rf",data=training_r,
                  trControl=cv_options)
stopCluster(cluster)
registerDoSEQ()
```

We compute the accuracy ratio using the resampling with bootstraping (0.9891) and the testing sample (0.9927).

```{r}
CM_rf_res<-confusionMatrix.train(mod_rf_res)
CM_rf_res_test<-confusionMatrix(predict(mod_rf_res,testing),as.factor(testing$classe))
```

Training of random forest with 5-fold cross-validation:

```{r, cache=TRUE}
set.seed(123)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
cv_options<- trainControl(method="cv",number=5,allowParallel = TRUE)
mod_rf_cv5<-train(classe ~ .,method="rf",data=training_r,
                   trControl=cv_options)
stopCluster(cluster)
registerDoSEQ()
```

We compute the accuracy ratio using the 5-fold cross-validation (0.991) and the testing sample (0.9932).

```{r}
CM_rf_cv5<-confusionMatrix.train(mod_rf_cv5)
CM_rf_cv5_test<-confusionMatrix(predict(mod_rf_cv5,testing),as.factor(testing$classe))
```

## Conclusions

In the previous section we have seen that from all the trained models the one with a highest out-of-sample accuracy ratio is a random forest fitted with 5-fold cross-validation. The out-of-sample accuracy ratio using 5-fold cross-validation is 0.991.

We can plot the importance of each variable in this "best" model (saved in R object mod_rf_cv5).

```{r}
plot(varImp(mod_rf_cv5))
```

In the graph above we can see that the most important variables are roll_belt, pitch_forearm and yaw_belt. As a curiosity, we can plot the predicted outcome in the testing sample in this three dimensions

```{r}
pred_rf_cv5<-predict(mod_rf_cv5,testing)
qplot(roll_belt, pitch_forearm, col = pred_rf_cv5, data = testing)
qplot(roll_belt, yaw_belt, col = pred_rf_cv5, data = testing)
qplot(pitch_forearm, yaw_belt, col = pred_rf_cv5, data = testing)
```